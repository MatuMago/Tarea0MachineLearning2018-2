{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Reggression by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4 align='center'> Fernanda Urrea, Rol:201551522-0, Matías Gómez, Rol: 201460501-3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se le pedirá que implemente la regresión lineal ordinaria a través del algoritmo SGD (*Stochastic Gradient Descend*) para encontrar los parámetros de la regresión a través de este algoritmo de manera iterativa. La técnica de SGD es sin duda dominante al momento de entrenar modelos en máquinas de aprendizaje cuando la solución no tiene un óptimo derivable analíticamente, en este caso la regresión lineal ordinaria que trabajaremos si tiene óptimo anaĺitico, sin embargo, se le pedirá que compare este caso con fines pedagógicos.\n",
    "\n",
    "* Regresión lineal ordinaria:\n",
    "$$\n",
    "\\hat{y} = f(\\vec{x}) =\\vec{\\beta}^T\\cdot \\vec{x}\n",
    "$$\n",
    "\n",
    "* Función objetivo:\n",
    "$$\n",
    "Loss = \\frac{1}{N} \\sum_i^N ( y_i - \\hat{y}_i )^2\n",
    "$$\n",
    "\n",
    "\n",
    "* Algoritmo SGD para regresión lineal ordinaria:\n",
    "$$ \\vec{\\beta}^{(t+1)} \\leftarrow \\vec{\\beta}^{(t)} - \\eta \\nabla_{\\vec{\\beta}^{(t)}} Loss $$\n",
    "\n",
    "Para lo que sigue de la actividad sólo podrá utilizar *numpy* (para operaciones de algebra lineal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Escriba una función que calcule la función de pérdida, error cuadrático medio (MSE - *mean squared error*), para un dato o para un conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Calcula_error_perdida(valores_reales,valores_estimados):\n",
    "    n=len(valores_estimados)\n",
    "    if len(valores_reales)==n:\n",
    "        vector_dif=valores_reales-valores_estimados\n",
    "        vector_dif_al_cuadrado=vector_dif**2\n",
    "        suma_cuadrados=np.sum(vector_dif_al_cuadrado)\n",
    "        Error=suma_cuadrados/n\n",
    "        return(Error)\n",
    "    else:\n",
    "        return(\"Error de dimensión\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Calcula_error_perdida(np.array([1,1,1]),np.array([-1,-1,-1])) #se comprueba la función de MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Escriba una función que calcule el gradiente (derivada) de la función de pérdida anterior, para un dato o para un conjunto de datos. *Escriba explícitamente la derivada (gradiente)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En la definición de la función asumimos que la funcion de perdida, \n",
    "#(Loss, según el enunciado) está fija\n",
    "\n",
    "def calcula_gradiente_LOSS(valores_reales, valores_estimados):\n",
    "    n=len(valores_estimados)\n",
    "    if len(valores_reales)==n:\n",
    "        vector_gradiente=np.zeros(n)\n",
    "        for i in range(n):\n",
    "            vector_gradiente[i]=2*(valores_estimados[i]-valores_reales[i])/n\n",
    "        return(vector_gradiente)\n",
    "    else:\n",
    "        return(\"Error de dimensión\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.33333333e+00, -6.66666667e-01,  6.66600000e+03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcula_gradiente_LOSS(np.array([1,1,1]),np.array([-1,0, 10000]))#Se comprueba la función"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Escriba una función que calcule los parámetros de una regresión lineal simple de manera analítica (es decir el mínimo global)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "def calcula_parametros_rl(X,y):\n",
    "    X_tran=X.transpose()\n",
    "    A=np.dot(X_tran,X)\n",
    "    A_inv=np.linalg.inv(A)\n",
    "    beta_aux=np.dot(X_tran,y)\n",
    "    beta=np.dot(A_inv,beta_aux)\n",
    "    return(beta)\n",
    "\n",
    "#Se necesita que el vector X tenga un campo expandido de puros 1, como se vio en cátedra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1facc60302f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#Comprobamos con la regresion lineal de sklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[0m__check_build\u001b[0m  \u001b[1;31m# avoid flakes unused variable error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m from .validation import (as_float_array,\n\u001b[0m\u001b[0;32m     12\u001b[0m                          \u001b[0massert_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                          \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMemorizedResult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPrintTime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_memory_helpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopen_py_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy_pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdisk\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmkdirp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrm_subdirs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemstr_to_bytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_compat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPY3_OR_LATER\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnumpy_pickle_compat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mZNDArrayWrapper\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_compat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPY3_OR_LATER\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbackports\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_memmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m###############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#EJEMPLO\n",
    "#Tomamos un vector X\n",
    "X=np.array([121,123,108,118,111,109,114,103,110,115])\n",
    "#Y un vector y\n",
    "y=np.array([25,22,19,24,19,18,20,15,20,21])\n",
    "#Expandimos el vector X\n",
    "X=np.c_[X,np.ones(X.shape[0])]\n",
    "#print(X)\n",
    "a=calcula_parametros_rl(X,y)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#Comprobamos con la regresion lineal de sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression()\n",
    "clf.fit(X, y)\n",
    "predicted = clf.predict(X)\n",
    "\n",
    "#Calculamos el error\n",
    "for i in range(10):\n",
    "    print(\"Error \",i,(predicted[i]-np.dot(a.transpose(),X[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo anterior, la regresión corresponde a y=0.42x-27.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Ahora escriba un programa que permita entrenar una regresión lineal a través del algoritmo SGD mostrado en la ecuación del algoritmo SGD, es decir, que de manera iterativa, vaya tomando un dato a la vez, y actualizando el parámetro $\\beta$ a través del gradiente descendiente de la función de pérdida de la regresión lineal ordinaria, de la pregunta b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6507926.25599884,   -59856.98923333])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iteracion(beta,eta,n,X,y):\n",
    "    B=len(X)\n",
    "    if B==len(y):\n",
    "        beta_tran=beta.transpose()\n",
    "        suma=0\n",
    "        for i in range(B):\n",
    "            e_i=(np.dot(beta_tran,X[i])-y[i])\n",
    "            x_i=X[i]\n",
    "            suma=suma+e_i*x_i\n",
    "        grad=2*n*suma/B\n",
    "        beta_nuevo=beta-eta*grad\n",
    "        return(beta_nuevo)\n",
    "    else:\n",
    "        print(\"ERROR\")\n",
    "        return(\"Error\")\n",
    "\n",
    "def entrenar(beta_inicial,X,y,eta,B):\n",
    "    cantidad_ejemplos=len(X)\n",
    "    cantidad_iteraciones=int(cantidad_ejemplos/B)-1\n",
    "    beta_nuevo=beta_inicial\n",
    "    for j in range(cantidad_iteraciones):\n",
    "        X_entra=X[0+B*j:B+B*j]\n",
    "        y_entra=y[0+B*j:B+B*j]\n",
    "        beta_nuevo=iteracion(beta_nuevo,eta,cantidad_ejemplos,X_entra,y_entra)    \n",
    "    return beta_nuevo\n",
    "    \n",
    "    \n",
    "    \n",
    "#Tomamos un vector X\n",
    "X=np.array([121,123,108,118,111,109,114,103,110,115])\n",
    "#Y un vector y\n",
    "y=np.array([22,22,19,24,19,18,20,15,20,21])\n",
    "#Expandimos el vector X\n",
    "X=np.c_[X,np.ones(X.shape[0])] \n",
    "entrenar(np.array([0.4,-27]),X,y,0.001,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def iteracion(beta,eta,n,X,y):\n",
    "#   B=len(X)\n",
    "#    if B==len(y):\n",
    "#        beta_tran=beta.transpose()\n",
    "#        suma=0\n",
    "#        for i in range(B):\n",
    "#            print(\"beta_tran: \",beta_tran,\"\\nX_i: \",X[i],\"\\ny[i]: \",y[i],\"\\nMulti: \",np.dot(beta_tran,X[i]))\n",
    "#            e_i=(np.dot(beta_tran,X[i])-y[i])\n",
    "#            x_i=X[i]\n",
    "#            suma=suma+e_i*x_i\n",
    "#            print(\"e_i:\",e_i,\"x_i:\",x_i,\"suma:\",suma)\n",
    "#        print(\"salió de iter\")\n",
    "#        grad=2*n*suma/B\n",
    "#        print(\"Grad: \",grad)\n",
    "#        producto=eta*grad\n",
    "#        print(\"producto: \",producto)\n",
    "#        beta_nuevo=beta-producto\n",
    "#        return(beta_nuevo)\n",
    "#    else:\n",
    "#        print(\"ERROR\")\n",
    "#        return(\"Error\")\n",
    "\n",
    "#def entrenar(beta_inicial,X,y,eta,B):\n",
    " #   cantidad_ejemplos=len(X)\n",
    " #   print(cantidad_ejemplos)\n",
    " #   cantidad_iteraciones=int(cantidad_ejemplos/B)-1\n",
    " #   print(cantidad_iteraciones)\n",
    " #   beta_nuevo=beta_inicial\n",
    " #   for j in range(cantidad_iteraciones):\n",
    " #       X_entra=X[0+B*j:B+B*j]\n",
    " #       y_entra=y[0+B*j:B+B*j]\n",
    " #       beta_nuevo=iteracion(beta_nuevo,eta,cantidad_ejemplos,X_entra,y_entra)    \n",
    " #       print(\"Beta_nuevo\",beta_nuevo)\n",
    " #   return beta_nuevo\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Demuestre que sus programas funcionan en un problema de regresión simple. Para esto utilice el dataset **Boston Housing** , disponible a través de la librería __[*sklearn*](http://scikit-learn.org)__, el cual corresponde a el precio de diferentes casas en Boston además de distintas características relevantes respecto al lugar, como por ejemplo el crimen en la ciudad, el número de habitaciones, que tan vieja es, distancia a lugares relevantes, entre otros. Éstas características deben combinarse linealmente para estimar el precio de la casa.\n",
    "<div class=\"alert alert-block alert-info\">Es una buena práctica el normalizar los datos antes de trabajar con el modelo</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train,y_train = load_boston(return_X_y=True)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "boston=load_boston()\n",
    "\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se utiliza nuestra funcion que calcula analiticamente\n",
    "\n",
    "X_train1=np.c_[X_train,np.ones(X_train.shape[0])]\n",
    "a=calcula_parametros_rl(X_train1,y_train)\n",
    "for i in range(10):\n",
    "    print(np.dot(a.transpose(),X_train1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se utiliza la funcion LinearRegression de sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "predicted = clf.predict(X_train)\n",
    "for i in range(10):\n",
    "    print(predicted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se Calcula el error para una cantidad fija de 30 datos\n",
    "for i in range(30):\n",
    "    print(\"Error \",i+1,\": \",abs(np.dot(a.transpose(),X_train1[i])-predicted[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que los errores entre la regresión lineal programada analiticamente por nosotros y la regresión lineal disponible en la libreria de sklearn son muy pequeños para el ejemplo que se tomó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora utilizamos el algoritmo de entrenamiento, tomando como vector $\\beta$ al vector nulo, un valor de $\\eta$ igual a $0.5$, Un valor de $B$ de $10$ y los conjuntos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-01977c139b91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mentrenar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train1' is not defined"
     ]
    }
   ],
   "source": [
    "b=entrenar(np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0]),X_train1,y_train,0.5,10)\n",
    "for i in range(10):\n",
    "    print(np.dot(b.transpose(),X_train1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
